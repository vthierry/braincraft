\documentclass{article}
\usepackage{graphicx}
\usepackage{url} \newcommand{\href}[2]{#2\footnote{\url{#1}}}
\usepackage{amsmath,amssymb,amsfonts}
\newcommand{\eqline}[1]{~\vspace{0.1cm}\\\centerline{$#1$}\vspace{0.1cm}\\}
\newcommand{\defq}{\stackrel {\rm def}{=}}
\newcommand{\tab}{\hphantom{4mm}}

\title{Programmatic solution}
\begin{document}

\section{Programmatoid braincraft challenge solution}

Let us consider the following digital experimental setup, as described in \href{https://github.com/rougier/braincraft/blob/master/README.md#introduction}{braincraft challenge presentation}.

\subsection{Simplified problem statement}

\centerline{\includegraphics[width=0.9\textwidth]{../../data/debug.png}}

\href{https://github.com/rougier/braincraft}{The braincraft challenge} bot moves at a constant with sensor inputs and one orientation output, it uses some energy and refill this energy on a given yellow location. The 2D space size is $[0, 1] \times [0, 1]$. The bot starts in the middle and oriented at $90°$, i.e., upward.

\begin{tabular}{|ll|l|}
  \hline\multicolumn{3}{|c|}{{\bf Input variables}}\\\hline
  $p_l \in [0_{\mbox{wall-hit}}, 1_{\mbox{no-wall}}[$ && \parbox{5cm}{Leftward proximity, {\small max value of the [0, +30°] range 32 left sensors.}} \\\hline 
  $p_r \in [0_{\mbox{wall-hit}}, 1_{\mbox{no-wall}}[$ && \parbox{5cm}{Rightward proximity, {\small max value of the [-30°, 0] range 32 right sensors. }} \\\hline 
  $c_{l\bullet} \in \{0, 1\}, \bullet \in \{b_{\mbox{blue}}, r_{\mbox{red}}\}$ && \parbox{5cm}{Leftward binary red and blue color detectors.}\\\hline 
  $c_{r\bullet}  \in \{0, 1\}, \bullet \in \{b_{\mbox{blue}}, r_{\mbox{red}}\}$ && \parbox{5cm}{Rightward binary red and blue color detectors.} \\\hline 
  $g_e \in [0_{\mbox{death}}, 1_{\mbox{full}}]$ && Energy gauge value. \\\hline 
  \hline \multicolumn{3}{|c|}{{\bf Output variable}}\\\hline
  $d_o \in [-5, 5]$ && Orientation difference, saturated at  $\pm$ 5°.\\\hline 
 \end{tabular} 

With respect to the original braincraft challenge:
\\ \tab - we consider two leftward and rightward ``average'' sensors only,
\\ \tab - color is input as binary variables, and always available,
\\ \tab - the wall hit indicator is not used.

\newpage \subsection{A putative controller}

\subsubsection{Input preprocessing}

\paragraph{Proximity sensors}\begin{description}
\item[Motivation] Simplifies the left-right navigation by compacting the leftward and rightward sensors as a simple pair of input.
\item[Implementation] A simple sum or average could be used, thus using directly a linearcombination of the input in afferent units. \\
  Then, if apropriate, the maximal and the average operators can be combined, e.g.\footnote{Let us derive the formula:
\\ - The series  at $\mu \rightarrow 0^+$ is easily obtained from any symbolic calculator writing, e.g.:
\\\centerline{{\tt series(log(sum(exp(mu * p[k]), k = 1..K)) / mu, mu = 0, 2);}} \\
\\- There is no obvious series development at $\mu \rightarrow +\infty$ but, considering $p[1] \le p[2] \le \cdots \le p[K]$, without loss of generality,
i.e., that -for the notation- index's order correspond to decreasing values, we obtain from straightforward algebra:\eqline{\begin{array}{c}
    \log\left(\sum_{k \in \{1\cdots K\}}  \, \exp(\mu \, p[k])\right) / \mu = p[1] + \rho / \mu\\
    \rho \defq \log\left(1 + \sum_{k \in \{2\cdots K\}}  \, \exp(-\mu \, (p[1] - p[k]))\right) \\
    \mbox{ with } 0 \le \rho \le \log\left(1 + (K-1) \, \exp(-\mu \, (p[1] - p[2]))\right) \le \log(K) \\
\end{array}}
so that $\lim_{\mu \rightarrow +\infty} \rho = 0$ and $\rho = o(\mu)$, yielding the expected result.}: \eqline{\begin{array}{rcl}
    p_{\dagger} &\leftarrow& \log\left(\sum_{k \in K}  \, \exp(\mu \, p[k])\right) / \mu \\
    &=& \frac{1}{K} \sum_k p_k + \log(K) / \mu + O(\mu) \\
    &=& \max_k(p[k]) + o\left(\frac{1}{\mu}\right) \\
\end{array}}
  where $K$ stands for the left or right sensor related indexes, $p[k]$ stands for the sensor proximity value,
  and  $\mu > 0$ parameterizes the balance between the max (for large $\mu$) and the average (for small $\mu$)  operators.
\end{description}
  
\paragraph{Color sensors}\begin{description}
\item[Motivations] Again, color blob detection is to perform either on the left or on the right, allowing the color input to be compacted. For each color, a channel is specified, simplifying the programmatoid implementation and providing an input closer to biological colored vision. Since the setup color input is a discrete color index, the channel value is binary, accounting for the presence, or not, of a least one related color index.  
\item[Implementation] For the distributed implementation, each camera color index value is mapped on each color channel input with the 0 value if the color is different and the 1 value if equal, e.g., using step unit: \eqline{\begin{array}{rcl}
    c_{\dagger\bullet} &\leftarrow& H(\sum_{k \in K}  \, (1 - D(i_{\bullet} - c[k]))), \\
    && \dagger \in \{l_{\mbox{left}}, r_{\mbox{right}}\}, \bullet \in \{b_{\mbox{blue}}, r_{\mbox{red}}\} \\
    D(x) &\defq& H(x-\epsilon) + H(-x-\epsilon)) = \mbox{ if } |x| < \epsilon \mbox{ then } 0 \mbox{ else } 1, \epsilon \ll 1 \\
\end{array}}
 where $K$ stands for the left or right sensor related indexes, $i_{\bullet}$ stands for the color index, and $c[k]$ stands for the sensor color index value.
\end{description}

\paragraph{Energy measurement}\begin{description}
 \item[Motivation] The energy is refilled during several steps, so that energy increase accumulation has to be pre-processed.
 \item[Processed Variables] 
  \eqline{\begin{array}{lll}
  g_{c\flat} \in [0, 1], \flat \in \(1, 2\} &\left.g_{c\flat} \right|_{t = 0} = 0 & \mbox{Last and last-before-last cumulative energy increases.}\\
  g_{i\flat} \in [0, 1], \flat \in \(0, 1\} &\left.g_{i\flat} \right|_{t = 0} = 0 & \mbox{Present and last instantaneous energy increases.}\\
  g_{e1} \in [0, 1]                               &\left.g_{e1} \right|_{t = 0} = 0 & \mbox{Last energy value.} \\
  \end{array}}
 \item[Implementation] \eqline{\begin{array}{lll}
      g_{i1} \leftarrow g_{i0}, & g_{i0} \leftarrow g_e - g_{e1}, & g_{e1} \leftarrow g_e \\
  \end{array}} thus implemented as linear computation units.
\end{description}

\subsubsection{Navigation}\begin{description}
\item[Heuristic]: The bot runs at constant velocity,
\\\tab (i) ahead by default, thanks to a linear correction, high enough to correct the direction, small enough to avoid oscillations, and
\\\tab (ii) attempts to perform a quarter-turn in the preferred orientation as soon as passing is detected.
\\With this navigation mechanism the bot performs either leftward or rightward half-loops, traversing the central corridor.
\item[Internal variable] \eqline{\begin{array}{lll}
  q_p \in \{0_{\mbox{leftward},} 1_{\mbox{rightward}}\}, &\left.q_p\right|_{t = 0} = 0 & \mbox{Preferred quarter-turn direction.} \\
\end{array}}
\item[Programmatoid solution]:\eqline{\begin{array}{rclcl}
    d_o &\leftarrow& \multicolumn{3}{l}{\underbrace{\gamma \, (p_l - p_r)}_{\mbox{\begin{tabular}{c}linear correction to \\ maintain direction ahead\end{tabular}}} +
                                                                   \underbrace{\alpha \, (t_l - t_r)}_{\mbox{\begin{tabular}{c}quarter- turn \\ left or right\end{tabular}}}} \\
    t_l &\leftarrow& (1- q_p) \, H(\beta - p_l) &=& H((\beta - p_l) - \upsilon \, q_p)\\
    t_r &\leftarrow& q_p \, H(\beta - p_r) &=& H((\beta - p_r) - \upsilon \, (1 - q_p)) \\
\end{array}}  where: \eqline{\begin{array}{rcll}
    w &\simeq& 1/4 & \mbox{\parbox{8cm}{Rough estimation of the path-width.}} \\
    \gamma &=& \frac{5}{w/2} & \mbox{\parbox{8cm}{Saturates the correction at 5° if the depth difference is half of the path-width.}} \\
    \alpha    &=& 90 & \mbox{\parbox{8cm}{Saturates the correction at $\pm$ 90° to make the quarter-turn, {\small since the linear $|\gamma \, (p_l - p_r)| < 40°$ is lower than the quarter-turn term, the latter submut the former.}}} \\
    \beta      &=& w & \mbox{\parbox{8cm}{Triggers the quarter-turn if the depth is higher than the path-width.}} \\
    \upsilon &=& 10 & \mbox{\parbox{8cm}{Transform a boolean product to a step-function threshold.}} \\
\end{array}} while: \eqline{\begin{array}{rclcl}
 t_l =1&\mbox{iff}& q_p = 0 &\mbox{and while}& \beta < p_l \\
 t_r =1&\mbox{iff}& q_p = 1 &\mbox{and while}& \beta < p_r \\
\end{array}}  in words: we execute the quater-turn until another wall is detected.
\end{description}

Regarding transforming a boolean product to a step-function threshold, we easily verify\footnote{
If $b = 0$ then the equality writes $0 = H(x - M)$, but $x < M$ so that $H(x - M) = 0$, thus verified, while if $b = 1$then the equality writes $H(x) = H(x)$, again verified.} that:
\eqline{b \in \{0, 1\}, x \in ]-M, M[  \Rightarrow b \, H(x) = H(x - (1 - b) \, M),}
for both values of $b$, while $\max(|\beta - p_l|, |\beta - p_r) \le 1$; this is developed and generalized in the sequel.

We thus have a linear output unit for $d_o$ and two step-unit for $t_l$ and $t_r$.

\newpage \subsubsection{Direction choices}

\subsubsection{Task 1: Simple decision} \begin{description}
  \item[Strategy] Restrict navigation to the half-loop that contains the energy source, while the other does not.
  \item[Heuristic] If the energy is too low, thus looping in the wrong direction, the direction is changed once. \\
      At start $q_p = 0$. Then, if the energy is too low it changes once to $q_p = 1$.\eqline{\begin{array}{l}
          q_p = \mbox{if } q_p = 1  \mbox{ or } \nu > g_e \mbox{then} 1 \mbox{ else } 0 \\
      \end{array}}
     \item[Programmatoid solution: \eqline{\begin{array}{rcl}
       q_p  &\leftarrow& H(\upsilon \, q_p + (\nu - g_e))
   \end{array}} where: \eqline{\begin{array}{rcll}
      c &=&1/1000 & \mbox{\parbox{8cm}{Energy consumption at each step.}}\\
      s &=&1/100 & \mbox{\parbox{8cm}{Speed: location increment at each steps.}}\\
      l &=& 3/2 & \mbox{\parbox{8cm}{Distance bound between the starting point and the putative energy sources.}}\\
      \nu &\simeq& l \, c/s = 3/20& \mbox{\parbox{8cm}{Energy consumption threshold if no source on the path.}}\\
  \end{array}}
\end{description}

\subsubsection{Task 1b: Simple decision but varying environment} \begin{description}
  \item[Strategy] Restrict navigation to the half-loop that contains the energy source, while the other does not, this may change with time.
  \item[Heuristic]~
    \\- If the energy is too low, the direction is inverted.
    \\-This is registered, avoiding multiple changes at low energy.
    \\-When the energy is high enough, change registration is reset.
    \item[Internal variable] \eqline{\begin{array}{lll}
        g_i \in \{0, 1\} & \left. g_i \right|_{t = 0} = 0 & \mbox{Detects the low energy, if not yet done.} \\
        g_c \in \{0, 1\} & \left. g_c \right|_{t = 0} = 0 & \mbox{Registers if the low energy has been already detected.} \\
    \end{array}}
    \item[Programmatoid solution] \eqline{\begin{array}{rclcl}
        \multicolumn{5}{l}{\mbox{Detects if the direction is to be changed.}} \\
        g_i &\leftarrow& \mbox{if } g_c = 0 \mbox{ and } \nu > g_e  \mbox{ then } 1 \mbox{ else } 0 &=& H(H(g_c - 1/2) \\ &&& +& H(g_e - \nu) - 3/2) \\
        \multicolumn{5}{l}{\mbox{Inverts the direction if to be changed.}} \\
        q_p &\leftarrow& \mbox{if } g_i = 0  \mbox{ then } q_p \mbox{ else } 1 - q_p &=& H(q_p  - 1/2 - \upsilon \, (1 - g_i)) \\&&&+& H(1/2 - q_p - \upsilon \, g_i) \\
        \multicolumn{5}{l}{\mbox{Registers the inversion until the energy is high enough.}} \\
        g_c &\leftarrow& \mbox{if } 2 \, \nu < g_e \mbox{ then } 0 \\ && \mbox{ elif } g_c = 1 \mbox{ then } 1 \mbox{ else } g_i &=&
        	H(g_i - 1/2 + \upsilon \, g_c - 2 \, \upsilon \, H(g_e - 2 \, \nu)) \\
    \end{array}}
\end{description} 

\subsubsection{Task 2: Cued environment decision} \begin{description}
  \item[Strategy] Restrict navigation to the half-loop without a closed path, as indicated by a color that has already been seen once.
    \item[Heuristic] Detect and store the first color blob, and choose to turn in the direction it appears again.
    \item[Internal variable] \eqline{\begin{array}{lll}
        c_{p\bullet} \in \{0, 1\} & \left. c_{p\bullet} i \right|_{t = 0} = 0 & \mbox{Color } \\
    \end{array}}
    \item[Programmatoid solution] \eqline{\begin{array}{rclcl}
         \multicolumn{4}{l}{\mbox{Detect the cue, if not yet done}} \\
        \mbox{if} & c_p = 0 \mbox{ and } c_l \ne 0 &\mbox{then} & c_p \leftarrow c_l \\
        \mbox{if} & c_p = 0 \mbox{ and } c_r \ne 0 &\mbox{then} & c_p \leftarrow c_r \\
        \multicolumn{4}{l}{\mbox{Set the direction according to the cue}} \\
        \mbox{if} & c_p \ne 0 \mbox{ and } c_l \ne 0 \mbox{ and } c_p = c_l &\mbox{then} & q_c \leftarrow 0 \\
        \mbox{if} & c_p \ne 0 \mbox{ and } c_r \ne 0 \mbox{ and } c_p = c_r &\mbox{then} & q_c \leftarrow 1 \\
        \multicolumn{4}{l}{\mbox{Reset the cue at a certain energy decrease}} \\
        \mbox{if} & g_e <  \kappa &\mbox{then} & c_p \leftarrow 0 \\
   \end{array}} \end{description}

blablab $c_{l\bullet} \in \{0, 1\}, \bullet \in \{b_{\mbox{blue}}, r_{\mbox{red}}\}$

\end{document}

   
 \item[Task 3]  Test both energy sources on the left and on the right and decide which one is better.
   \begin{description}\item[Heuristic] When energy increase occurs if the previous energy increase is higher, change direction. \eqline{\begin{array}{rclc}
         \multicolumn{4}{l}{\mbox{Updates the energy gauge increase.}}
           g_d \leftarrow g_e - g_{e1}, g_{e1} \leftarrow g_e, g_{d1} \leftarrow 
 \end{array}}

   \end{description}




\begin{description}
  
\end{description}

\clearpage

\paragraph{Programmatoid solution}:
\eqline{\begin{array}{rcl}
    \lambda &=& \lambda + \Delta\lambda_1 + \Delta\lambda_2 + \Delta\lambda_3 + \cdots \\
    \Delta\lambda_1 &=& (\lambda - 1) \, H(\alpha - \varepsilon) \\
    \Delta\lambda_2 &=& (\lambda - 1) \, H(\iota - I_{\mbox{left blue color sensor}}) \\
    \Delta\lambda_3 &=& (\lambda - 1) \, (\Upsilon_{\mbox{again red color}} + \Upsilon_{\mbox{again yellow color}} + \cdots) \\
    \cdots &&\\
    \Upsilon_{\mbox{again this color}} &=& \Upsilon_{\mbox{seen this color}} \, H(\iota - I_{\mbox{left this color sensor}}) \\
    \Upsilon_{\mbox{seen this color}} &=& \Upsilon_{\mbox{seen this color}}  + (1 - \Upsilon_{\mbox{seen this color}}) \, H(\iota - I_{\mbox{this color sensor}}) \\
    \cdots &&\\
\end{array}}
where: \begin{description}
  \item[$\alpha$] is a the energy threshold, corresponding to the energy consumption during one turn.
  \item[$\iota$] is some color detection threshold.
  \item[$\Delta\lambda_1$] raises to one if the energy decreases below a threshold.
  \item[$\Delta\lambda_2$] raises to one if the blue color is seen on the left.
  \item[$\Delta\lambda_3$] raises to one if some color is seen again.
  \item[$\Upsilon_{\mbox{\normalfont again this color}}$] raises to one  a previously seen color is seen again on the left.
  \item[$\Upsilon_{\mbox{\normalfont seen this color}}$] raises to one  a color is seen for the first time.
  \item[$I_{\mbox{\normalfont left this color sensor}}$] combines color sensor input.
  \item[$I_{\mbox{\normalfont this color sensor}}$] combines left and right color sensor input.
\end{description}



\clearpage

\paragraph{Neuronoid implementation}: The mollification of this system uses 3 neuronoids and writes:
\eqline{\begin{array}{rcl}
    d\theta &=& h\left(\gamma \, (\theta_l - \theta_r)+ \frac{\pi}{2} \, (\Delta\theta_r - \Delta\theta_l)\right)\\
    \Delta\theta_r &=& h(W_\infty \, (\beta - \theta_r) + 2\, W_\infty \, (\lambda - 1)) \\
    \Delta\theta_l &=& h(W_\infty \, (\beta - \theta_l) - 2\, W_\infty \, \lambda) \\
\end{array}}
as easily verified considering the four cases $\beta \lessgtr \theta_*$ versus $\lambda \in \{0, 1\}$.

With respect to the programmatoid solution, the output value is ``saturated'' by the $h(\cdot)$ function while the $\Delta\theta_*$ almost binary values are approximated by the mollification of the step function. This part of the system is feed-forward thus without convergence or stability issue.

\clearpage


\subsubsection{Computation unit: neuronoid}

By ``neuronoid'' we name the \href{https://en.wikipedia.org/wiki/Biological_neuron_model#Relation_between_artificial_and_biological_neuron_models}{not very biologically plausible} simplest biological neuron or neuron small ensemble inspired by \href{https://inria.hal.science/cel-01095603v1}{mean-field modelisation} of the \href{https://en.wikipedia.org/wiki/Hodgkin-Huxley_model}{Hodgkin–Huxley neuronal axon model}.

\eqline{\begin{array}{cc}
  \tau \frac{\partial v_i}{\partial t}(t) + v_i(t) = z_i(t), &
  z_i(t) \defq h\left(\sum_j \, w_{ij} \, v_j(t) + w_{i}\right), \\
  h(v) \defq \frac{1}{1+\exp(-4\,v)}, &
  H(v) \defq \left\{\begin{array}{rcl} 1 &\mbox{if}& v > 0\\ 0 &\mbox{if}& v < 0\\ \end{array}\right. \\
\end{array}}
where $v_i$ is the membrane potential, so that:
\eqline{\begin{array}{rcl} v(t)
  &=& 1/\tau \, \int_0^t z(s) \, exp(-(t-s)/\tau) \, ds + v(0) \, exp(-t/\tau) \\
  &=& \left. z(0) + (v(0) - z(0)) \, e^{-t/\tau} \right|_{z(t)= z(0)}. \\
  &=& \left. z(t) \right|_{\tau = 0} \\
  &\simeq&  (1-\gamma) \, v(t-\Delta t) + \gamma \, z(t-\Delta t)) \\
  &=& \sum_{s=0}^{t-1} z(s) \, \gamma \, (1-\gamma)^{t-s+1} \, z(s) + v(0) \, (1-\gamma)^t \\
  &=& \left. z(0) + (v(0) - z(0)) \,  (1-\gamma)^t \right|_{z(t)= z(0)} \\
  &=& \left. z(t) \right|_{\gamma = 1}. \\
\end{array}}
writing also the  corresponding discrete approximation using an Euler schema with $0 < \gamma < 1, 0 < \tau$:
\eqline{\begin{array}{c}\gamma \defq 1 - \exp(-1/\tau) \Leftrightarrow \tau = 1/\log(1/(1-\gamma)) \\  \lim_{\gamma \rightarrow 0} \tau = +\infty , \lim_{\gamma \rightarrow 1} \tau = 0. \end{array}}

Here,  $h(\cdot)$ is the normalized sigmoid with $h(-\infty) = 0, h(0) = 1/2, h'(0) = 1, h(+\infty) = 1$, linearly related to the hyperbolic function:
\eqline{h(v) = \frac{1 + \tanh(2 \, v)}{2}.}

It is the mollification of the step function, called also Heaviside function, $H(\cdot)$, as detailed below.

It is thus a very common 1st order ``neuronoid'' model, but with an adjustable bias (or offset) $w_{i}$.

\subsection{Programmatoid and neuronoid computation}

\subsubsection{Programmatoid  computation}

We name ``programmatoid'' computation the conception of an input-output \href{https://en.wikipedia.org/wiki/Straight-line_program}{straight-line program} implementing test operator on numerical value expressions using the step function, considering $1$ as the true value and $0$ as the false value. The $H(v)$ implements the test of the positive sign of $v$, while for $v_i \in \{0, 1\}$:
\begin{description}
  \item[programmatoid conjunction]  The $v_0 = H(v_1 + v_2 + \cdots)$ formula performs a {\em or} operation.
  \item[programmatoid disjunction]  The $v_0 = v_1 \, v_2 \cdots$ formula performs a {\em and} operation.
  \item[programmatoid negation]  The $v_0 = (1- v_1)$ formula performs a negation.
\end{description}
so that we can combine any boolean expression on any test of value sign, thus value comparison, and value interval inclusion, switches between two expressions, etc. This defines \href{https://en.wikipedia.org/wiki/Real_algebraic_geometry}{real semi-algebraic} sets of degree 1.

Using local feedback we can also design several functions detailed in the Appendix of this section, while we also can combine neuronoid and programmatoid functions to design temporal functions.

\subsubsection{Mollification of the step function}

The step function is related to a conditional expression by a simple relation:
\eqline{H(v) = conditional\;value > 0 \mbox{ ? } 1 \mbox{ : } conditional\;value < 0 \mbox{ ? } 0 \mbox{ : } H(0),}
where $condition \mbox{ ? } value\;if\;true \mbox{ : } value\;if\;false$ is a conditional expression.

The step function approximates sigmoid with huge slope at zero, i.e.:
\eqline{\forall v \ne 0, H(v) = \lim_{W_{\infty}  \rightarrow +\infty} h(W_{\infty} \, v), \left. h'(W_{\infty} \, v)  \right|_{v = 0} =  W_{\infty}}
while the convergence is also obtained for $v=0$ in the distribution sense with $H(0) = h(0) = 1/2$.
More precisely:
\eqline{|H(\cdot) - h(\cdot)|_{{\cal L}_1} = \frac{\log(2)}{2} \, \frac{1}{W_{\infty}}}
and, for $0 < \epsilon_\infty \ll 1 < v_\infty$:
\eqline{h(W_{\infty} \, v_\infty ) = 1 - \epsilon_\infty
  \Leftrightarrow v_\infty  =
 \frac{\log(1-\epsilon_\infty) -\log(\epsilon_\infty)}{4\,W_\infty} =
 \frac{-\log(\epsilon_\infty)}{4\,W_\infty} + O\left(\epsilon_{\infty}\right).}

Numerically, the convergence is very fast, e.g. $W_\infty = 2$, for $\epsilon_\infty = 0.1\%$:
\\\centerline{\begin{tabular}{|l|c|c|c|c|} \hline
  $\epsilon_\infty$ & $10^{-1}$ & $10^{-2}$ & $10^{-3}$ & $10^{-6}$ \\ \hline
  $W_\infty$ & 0.55 & 1.15 & 1.73 & 3.46 \\
  \hline \end{tabular}}
  
A step further, the local variation of sigmoid writes:
\eqline{\begin{array}{rcl} h(v)
    &=& h(v_0) + \left[ 4 \, \exp(-8 \, v_0)+ O\left(\exp(-12 \, v_0))\right) \right] \, (v - v_0) + O\left((v - v_0)^2\right) \\
    &\simeq& h(v_0) + 4 \, \exp(-8 \, v_0)  \, (v - v_0). \\ \end{array}}
Numerically, values decrease very rapidly:
\\\centerline{\begin{tabular}{|l|c|c|c|c|} \hline
  $v_0$                                      & $1$          & $2$           & $5$          & $10$ \\ \hline
  $4 \, \exp(-8 \, v_0) \simeq$ & $10^{-1}$ & $10^{-3}$ & $10^{-8}$ & $10^{-17}$ \\
  \hline \end{tabular}}

\subsubsection{Neuronoid  implementation of programmatoid computation}

We call ``neuronoid'' computation the conception of an input-output transform based on feed-forward and recurrent combination of neuronoids, as defined previously.

By successive combination, any programmatoid  computation involving the $H(\cdot)$ function can be approximated by a neuronoid, with $\tau \simeq 0$.

A step ahead, we considering neuronoid with $\tau > 0$ it seems obvious that we can designed temporizing mechanisms, oscillators and sequence generator, sleep sort mechanism, etc. (not detailed here because not used at this stage,  see appendix).

\paragraph{Neuronoid implementation}: The mollification uses 3 neuronoids for cases 1 and 2 plus 3 neuronoids by color for case 3. The derivation of the neuronoid equations is straightforward after the previous one.

\subsection{Appendix: a few programmatoid and neuronoid components}

\subsubsection{Conditional expression}

For two inputs $v_{i1}(t) \in \{0, 1\}, v_{i0}(t) \in \{0, 1\}$, an output $v_o(t) \in \{0, 1\}$ and a control $v_l \in \{0, 1\}$, the condition expression equation, for $0 < W_\delta \ll 1 < W_\sigma$ :
\eqline{\begin{array}{rcll}  v_o(t+1)
    &=& v_l(t) == 1 \mbox{ ? } v_{i1}(t) \mbox{ : } v_{i0}(t) & (1) \\
    &=& v_l(t) \, v_{i1}(t)  + (1- v_l(t)) \, v_{i0}(t) & (2) \\
    &=& H(v_{i1}(t) - W_\sigma \, (1 - v_l(t)) - W_\delta) + H(v_{i0}(t) - W_\sigma \, v_l(t) - W_\delta)  & (3) \\
    &\simeq& h(W'_\infty \, (W_\omega \, v_{i1}(t) - W_\sigma \, (1 - v_l(t)) - W_\delta)) \\ &+& h(W'_\infty \, (W_\omega  \, v_{i0}(t) - W_\sigma \, v_l(t) - W_\delta)). & (4) \\
\end{array}}

To explain these design choices, let us notice that:

\begin{itemize}
\item The $W_\sigma$ value is used at the programmatoid level to ensure that given the $v_l(t)$ binary switch value, it constraints the step function output to correspond to the desired value. Here, an expression including a product by a binary function, is replaces by a sum. The rationale is that there is no explicit multiplication between two variables at the neuronoid level. This trick allows one a straightforward neuronoid approximation.
\item The $W_\delta$ value is used at the programmatoid level to avoid the ambiguous $0$ value and ensure that for $v\simeq0$  we obtain $H(v - W_\delta) = 0$.
\item The $W'_\infty$ gain is used to approximate the step function by a sigmoid, as discussed previously.
\item Informally, at the neuronoid level, we mimic the programmatoid mechanisms, assuming that suitable $W'_\infty, W_\omega, W_\sigma, W_\delta$ values will reproduced the programmatoid conditional expression. It works, although the parameter adjustment is not obvious, as derived now.
\end{itemize}

Let us now verify the equivalence between these equations:

\begin{itemize}

\item It is obvious to verify that line (1) and (2) are equivalent.

\item The fact line (2) and (3) are equivalent is verified by this truth table: \\
\centerline{\scriptsize \begin{tabular}{|c|c|c||c|c|c|} \hline
    $v_l(t)$ & $v_{i1}(t)$ & $v_{i0}(t)$ &  $v_{i1}(t) - W_\sigma \, (1 - v_l(t)) - W_\delta$ & $v_{i0}(t) - W_\sigma \, v_l(t) - W_\delta$ & $v_o(t+1)$ \\ \hline
    $1$ & $0$ & $0$ & $- W_\delta < 0$ & $-W_\sigma - W_\delta < 0$ & 0 + 0 = 0 = $v_{i1}(t)$ \\
    $1$ & $0$ & $1$ & $- W_\delta < 0$ & $1 - W_\sigma - W_\delta< 0$ & 0 + 0 = 0 = $v_{i1}(t)$ \\
    $1$ & $1$ & $0$ & $1 - W_\delta > 0 $ & $-W_\sigma - W_\delta< 0$ & 1 + 0 = 1 = $v_{i1}(t)$ \\
    $1$ & $1$ & $1$ & $1 - W_\delta > 0$ & $1 - W_\sigma - W_\delta< 0$ & 1 + 0 = 1 = $v_{i1}(t)$ \\
    $0$ & $0$ & $0$ & $- W_\sigma -W_\delta < 0$ & $- W_\delta< 0 $ & 0 + 0= 0 = $v_{i0}(t)$ \\
    $0$ & $0$ & $1$ & $- W_\sigma - W_\delta < 0 $ & $1 - W_\delta > 0$ & 0 + 1= 1 = $v_{i0}(t)$ \\
    $0$ & $1$ & $0$ & $1 - W_\sigma - W_\delta< 0 $ & $- W_\delta > 0 $ & 0 + 0= 0 = $v_{i0}(t)$ \\
    $0$ & $1$ & $1$ & $1 - W_\sigma - W_\delta< 0 $ & $1 - W_\delta > 0 $ & 0 + 1= 1 = $v_{i0}(t)$  \\
    \hline\end{tabular}}

\item The approximation of line (3) at line (4) by continuous quantities corresponds now to:
  \eqline{v_*(t) \in \{[0,\epsilon_\infty], [1 - \epsilon_\infty, 1]\} = \{\simeq 0, \simeq 1\}, \epsilon_\infty \ll 1/2,}
  in words: values to be either below or above a threshold close to either $0$ or $1$.
  The truth table now involves intervals and has been generated using the \href{https://github.com/vthierry/braincraft/raw/master/data/programmatic-solution.mpl.txt.out}{computer algebra piece of code associated to this document}. Considering the following intuitive design constraints:
  \eqline{0 <W_\delta < \{W_\omega,W_\sigma\}, 0 <W_\omega<W_\sigma, 0 < \epsilon_\infty < 1}
  the computer algebra derivations show that the approximation at line (4) is valid as soon as:
  \eqline{W_\omega \, \epsilon_\infty < W_\delta, W_\sigma \, \epsilon_\infty < W_\delta, W_\delta + (W_\omega + W_\sigma) \, \epsilon_\infty  < W_\omega.}

 Furthermore, let us consider the margin:
 \eqline{0 < \mu = \min(W_\delta - \epsilon_\infty \, W_\sigma, W_\omega - (W_\omega + W_\sigma) \, \epsilon_\infty - W_\delta),}
yielding:
\eqline{|v_o(t+1) - 1/2| > h(W'_\infty \, \mu).}
We thus can adjust $W'_\infty = W_\infty / \mu$ in order $v_o(t+1) \in \{[0,\epsilon_\infty], [1 - \epsilon_\infty, 1]\}$ for further calculation. 
 
For instance $\{W_\delta = 1, W_\omega = 2, W_\sigma = 4, \epsilon_\infty = 1/8\}$ is a suitable solution with $\mu = 1/4$.

\end{itemize}

\subsubsection{RS input/output gate}

For an input $v_i(t) \in \{0, 1\}$, an output $v_o(t) \in \{0, 1\}$, and a control $v_l \in \{0, 1\}$, the equation:
\eqline{\begin{array}{rcl}  v_o(t+1)
    &=& v_l(t) == 1 \mbox{ ? } v_o(t) \mbox{ : } v_i(t), \\
    &=& v_l(t) \, v_o(t)  + (1- v_l(t)) \, v_i(t) \\
    &=& H(v_{o}(t) - W_\sigma \, (1 - v_l(t)) - W_\delta) + H(v_{i}(t) - W_\sigma \, v_l(t) - W_\delta)  \\
    &\simeq& h(W'_\infty \, (W_\omega \, v_{o}(t) - W_\sigma \, (1 - v_l(t)) - W_\delta)) \\ &+& h(W'_\infty \, (W_\omega  \, v_{i}(t) - W_\sigma \, v_l(t) - W_\delta)). \\
\end{array}}
implements a 1 bit memory, i.e., also called a RS gate, and reusing the previous conditional instruction parameters.

The key point is that it is now a recurrent system, which stability is obvious at the programmatoid level, but not necessarily at the neuronoid level, since we have a continous equation.  More precisely:
\eqline{\begin{array}{c}v_o(t+1) = h(W'_\infty \, W_\omega \, v_{o}(t) - W_\beta(t)) + h_\beta(t), \\ \left\{\begin{array}{rcl} W_\beta &\defq& W_\sigma \, (1 - v_l(t)) + W_\delta \\ h_\beta(t) &\defq&  h(W'_\infty \, (W_\omega  \, v_{i}(t) - W_\sigma \, v_l(t) - W_\delta)) \in [-1, 1] \end{array} \right. \end{array}}
with a non contracting recurrent function, since:
\eqline{h'(W'_\infty \, W_\omega \, v) > 1$ for $|v| \leq W'_\infty \, W_\omega.}
        
  


\begin{description}
  \item[monostable binary value] The $v_0 = v_0  + (1 - v_0) \, H(v_1)$ formula sets $v_0$ to 1 for ever, as soon $v_1$ has raised once to 1.
\end{description}
and by combination RS gates,  bistable mechanisms, etc. (not detailed here because not used at this stage, see appendix).

To be done.

%\subsubsection{Monostable binary value}

%avec l = l/2 + h() si neuronoid pour avoir v fini

%\subsubsection{Bistable binary value}

%Then: emporizing mechanisms, oscillators and sequence generator, sleep sort mechanism, 

\section{Using the braincraft challenge setup}

Reference: \href{https://github.com/rougier/braincraft}{The braincraft challenge}.

You must be familiar with basic {\tt git} usage and basic {\tt python} programmation.

\subsection{Installation of the setup}
~
\\- Connect to {\tt https://github.com} with your login.
\\- Go to the \href{https://github.com/rougier/braincraft}{braincraft challenge} and create a new fork:
\\\centerline{\includegraphics[width=0.9\textwidth]{tuto1.png}}
\\- Download the repository in SSH read/write mode:
\\\centerline{\includegraphics[width=0.9\textwidth]{tuto2.png}}
\\-In the braincraft local git directory, run {\tt make test}
\\~~~~~ + You may have to run {\tt make install}, before.
\\~~~~~ + You are advised to use a virtual environment, running {\tt make venv}

\subsection{Running at the programmatic level}

\href{https://raw.githack.com/vthierry/braincraft/master/braincraft/doc/challenge_callback.html}{API doc}

The `challenge\_callback\_1.py`  file contains the support routines 


%The {\tt def next(input)} function that takes the {\tt input = depth\_l, color\_l, depth\_r, color\_r, energy} date structure and output the {\tt d\_o} where a stands for the orientation is to be defined.

%The {\tt programmatic.py} code provides all functions to evaluate the implementation, without training phase.
  
\subsection{Running at the artificial neural network level}

%The  {\tt def weights()}  function returning the fixed pre-compiled parameters {\tt weights = win, w, wout} is to be defined.

%The {\tt neuronoid.py} code provides all functions to evaluate the implementation, without training phase. 

\begin{verbatim}

* Note : vthierry veut PAS gagner la compétition is veut just vérifier des hypothèse quant la calculabilité avec des neuronoid.

- Warningup : duration (bot don't move before warmup period is over) just 1 to allow a 1st input ... ou bien c est plus subtil ?

- Quelles dimensions pour Win (quelles entrées où ? le truc de dimension P), W, et Wout(ligne ou colonne) ?

- Avis sur calcul de depth et couleur ?
 + depth: prendre le min des capteurs de gauche/droite ou vaut mieux leur moyenne pondérée ?
 + couleur: les murs ont le vert comme couleur par defaut ? prendre la valeur de couleur la plus nombreuse hormis celle du mur est pertinent ?

- Pour expérimenter l'approche programmatique avant de passer à l'approche connexiviste :
 - comment ``débrancher´´ le réseau et just avoir (P inputs) -> output ? sans reimplementer tout evaluate() ? 

- Pour expérimenter l'approche connectiviste sans apprentissage … juste implémenter def train(func, timeout=100.0): ... c est quoi ``func´´ ?

\end{verbatim}

\end{document}
